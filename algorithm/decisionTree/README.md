# 决策树
## 构造
* 选择哪个属性作为跟节点
* 选择哪些属性作为子节点
* 什么时候停止作为叶子节点
## 剪裁
* 过拟合：训练得到的模型太好了，过于契合产生死板的现象。
* 欠拟合：训练的模型不太好，致使分类错误
* 泛能力：模型的适应度好，叫泛能力好。不会过度拟合也不会欠拟合
* 剪枝方法
    * 预剪枝
    * 后剪枝
## 如何构建决策树
* 纯度：歧义大小表示纯度，歧义越小纯度越大反之亦然
* 信息熵：信息的不确定度用熵来描述，越大越不确定，信息量越大
* 构建决策时我们希望熵大或纯度低的项做跟节点或者父节点，熵越大表示信息量越大，纯度越高越能清晰决策
* 构建决策树经典算法
    * ID3 算法
    []()
    * C4.5 算法：在ID3的算法基础上，将信息增益/信息熵得到比率，并且有如下优化
        * 采取增益率
        * 悲观剪枝
        * 离散化处理连续性
        * 处理缺失值
    * Cart 算法
        * 分类树：采用基尼指数来衡量纯度，基尼指数越小说明纯度越高，可以当节点。
        * 回归树：纯度如下表示
            * 最小绝对偏差（LAD）
            * 最小二乘偏差（LSD）
        * 回归树使用CCP 剪枝
        
* 构造决策树的步骤
    * 根据信息增益或者信息增益率来选择特征
    * 生成决策树 ID3 C4.5 或者CART
    * 剪枝来增强模型泛能力
## 实战 泰坦尼克号生存预测
1. 数据分析，查看数据缺失情况
2. 数据清洗，将缺失数据不足
3. 数据矩阵化，一些不是数据化的特征，这些特征可以通过矩阵转化的方式进行处理
4. 决策树，形成模型
5. 查看决策树预测结果
6. 在没有测试集的情况下，可以通过k折交叉验证的方式进行结果预测     